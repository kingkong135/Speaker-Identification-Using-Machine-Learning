{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from hmmlearn.hmm import GMMHMM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1))\n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Đăng nhập dataset\n",
      "Load Đăng xuất dataset\n",
      "Load Khóa máy dataset\n",
      "Load Tìm kiếm dataset\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class_names = ['Đăng nhập', 'Đăng xuất', 'Khóa máy', 'Tìm kiếm']\n",
    "dataset = {}\n",
    "dataset_train = {}\n",
    "dataset_test = {}\n",
    "\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(\"data/câu lệnh/Tổng hợp\", cname))\n",
    "#     uncomment to shuffle dataset\n",
    "    random.shuffle(dataset[cname])\n",
    "    train_size = int(0.8*len(dataset[cname]))\n",
    "    dataset_train[cname] = dataset[cname][:train_size]\n",
    "    dataset_test[cname] = dataset[cname][train_size:]\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "# print(\"vectors\", all_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "# Comment KMEANS for GMMHMM\n",
    "# kmeans = clustering(all_vectors)\n",
    "# print(\"centers\", kmeans.cluster_centers_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangnhap_param = [\n",
    "    18,\n",
    "    np.array([1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
    "    np.array([\n",
    "        [0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangxuat_param = [\n",
    "    21,\n",
    "    np.array([1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
    "    np.array([\n",
    "        [0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "khoamay_param = [\n",
    "    15,\n",
    "    np.array([1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
    "    np.array([\n",
    "        [0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "    \n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timkiem_param = [\n",
    "    18,\n",
    "    np.array([1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
    "    np.array([\n",
    "        [0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    \"Đăng nhập\": dangnhap_param,\n",
    "    \"Đăng xuất\": dangxuat_param,\n",
    "    \"Khóa máy\": khoamay_param,\n",
    "    \"Tìm kiếm\": timkiem_param,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -929618.7646             +nan\n",
      "         2     -807072.4818     +122546.2828\n",
      "         3     -789207.9276      +17864.5542\n",
      "         4     -784407.0476       +4800.8801\n",
      "         5     -782797.4561       +1609.5915\n",
      "         6     -782008.3839        +789.0722\n",
      "         7     -781503.5643        +504.8196\n",
      "         8     -781170.7455        +332.8188\n",
      "         9     -780937.5254        +233.2201\n",
      "        10     -780797.5033        +140.0221\n",
      "        11     -780704.0794         +93.4239\n",
      "        12     -780649.4389         +54.6405\n",
      "        13     -780598.2293         +51.2095\n",
      "        14     -780542.8784         +55.3510\n",
      "        15     -780473.1509         +69.7274\n",
      "        16     -780402.1855         +70.9654\n",
      "        17     -780324.5463         +77.6392\n",
      "        18     -780256.9888         +67.5575\n",
      "        19     -780197.6847         +59.3041\n",
      "        20     -780147.3217         +50.3630\n",
      "        21     -780100.7249         +46.5968\n",
      "        22     -780068.7216         +32.0032\n",
      "        23     -780037.3518         +31.3698\n",
      "        24     -780022.3283         +15.0235\n",
      "        25     -780008.8483         +13.4800\n",
      "        26     -779994.8658         +13.9825\n",
      "        27     -779961.3989         +33.4669\n",
      "        28     -779938.7191         +22.6798\n",
      "        29     -779928.8659          +9.8532\n",
      "        30     -779923.1035          +5.7624\n",
      "        31     -779917.7409          +5.3626\n",
      "        32     -779910.9645          +6.7764\n",
      "        33     -779902.7700          +8.1945\n",
      "        34     -779894.9288          +7.8412\n",
      "        35     -779887.6679          +7.2609\n",
      "        36     -779880.8812          +6.7867\n",
      "        37     -779875.8648          +5.0164\n",
      "        38     -779871.4407          +4.4241\n",
      "        39     -779867.1227          +4.3179\n",
      "        40     -779862.8343          +4.2884\n",
      "        41     -779858.5454          +4.2889\n",
      "        42     -779854.2846          +4.2609\n",
      "        43     -779850.1270          +4.1576\n",
      "        44     -779846.0111          +4.1159\n",
      "        45     -779841.7792          +4.2319\n",
      "        46     -779837.3502          +4.4289\n",
      "        47     -779832.7318          +4.6184\n",
      "        48     -779827.8786          +4.8532\n",
      "        49     -779822.5925          +5.2861\n",
      "        50     -779816.7707          +5.8219\n",
      "        51     -779811.1636          +5.6071\n",
      "        52     -779805.8622          +5.3015\n",
      "        53     -779800.4744          +5.3878\n",
      "        54     -779794.5965          +5.8779\n",
      "        55     -779784.3420         +10.2545\n",
      "        56     -779776.4865          +7.8554\n",
      "        57     -779770.2425          +6.2440\n",
      "        58     -779764.0505          +6.1920\n",
      "        59     -779757.8159          +6.2346\n",
      "        60     -779750.4862          +7.3297\n",
      "        61     -779733.1539         +17.3323\n",
      "        62     -779702.4085         +30.7454\n",
      "        63     -779652.5037         +49.9048\n",
      "        64     -779624.3245         +28.1792\n",
      "        65     -779619.8512          +4.4733\n",
      "        66     -779618.5662          +1.2849\n",
      "        67     -779613.3170          +5.2493\n",
      "        68     -779601.0150         +12.3019\n",
      "        69     -779600.2608          +0.7542\n",
      "        70     -779599.6114          +0.6494\n",
      "        71     -779599.1141          +0.4973\n",
      "        72     -779598.7300          +0.3841\n",
      "        73     -779598.3934          +0.3366\n",
      "        74     -779598.0813          +0.3121\n",
      "        75     -779597.7867          +0.2946\n",
      "        76     -779597.5042          +0.2825\n",
      "        77     -779597.2278          +0.2764\n",
      "        78     -779596.9542          +0.2736\n",
      "        79     -779596.6901          +0.2641\n",
      "        80     -779596.4443          +0.2458\n",
      "        81     -779594.5090          +1.9353\n",
      "        82     -779583.4759         +11.0331\n",
      "        83     -779581.7419          +1.7340\n",
      "        84     -779581.0987          +0.6431\n",
      "        85     -779580.5214          +0.5774\n",
      "        86     -779579.6155          +0.9058\n",
      "        87     -779577.3677          +2.2479\n",
      "        88     -779573.9284          +3.4392\n",
      "        89     -779572.6722          +1.2562\n",
      "        90     -779571.4715          +1.2007\n",
      "        91     -779570.0969          +1.3746\n",
      "        92     -779569.2481          +0.8488\n",
      "        93     -779568.4961          +0.7520\n",
      "        94     -779567.7085          +0.7876\n",
      "        95     -779566.8623          +0.8462\n",
      "        96     -779565.9461          +0.9162\n",
      "        97     -779564.9606          +0.9855\n",
      "        98     -779563.9219          +1.0387\n",
      "        99     -779562.8491          +1.0729\n",
      "       100     -779561.7469          +1.1022\n",
      "       101     -779560.6084          +1.1384\n",
      "       102     -779559.4273          +1.1812\n",
      "       103     -779558.2051          +1.2222\n",
      "       104     -779556.9539          +1.2512\n",
      "       105     -779555.6881          +1.2657\n",
      "       106     -779554.4161          +1.2721\n",
      "       107     -779553.1398          +1.2763\n",
      "       108     -779551.8589          +1.2809\n",
      "       109     -779550.5754          +1.2834\n",
      "       110     -779549.3054          +1.2700\n",
      "       111     -779548.0743          +1.2311\n",
      "       112     -779546.8960          +1.1783\n",
      "       113     -779545.7770          +1.1190\n",
      "       114     -779544.7221          +1.0550\n",
      "       115     -779543.7255          +0.9965\n",
      "       116     -779542.7669          +0.9586\n",
      "       117     -779541.7950          +0.9719\n",
      "       118     -779540.6303          +1.1647\n",
      "       119     -779539.0729          +1.5574\n",
      "       120     -779537.8792          +1.1937\n",
      "       121     -779536.6244          +1.2547\n",
      "       122     -779531.2854          +5.3391\n",
      "       123     -779524.0383          +7.2471\n",
      "       124     -779515.1918          +8.8464\n",
      "       125     -779508.2018          +6.9901\n",
      "       126     -779500.9161          +7.2857\n",
      "       127     -779493.8044          +7.1117\n",
      "       128     -779491.8505          +1.9539\n",
      "       129     -779490.5864          +1.2642\n",
      "       130     -779489.5120          +1.0744\n",
      "       131     -779488.5425          +0.9695\n",
      "       132     -779487.5615          +0.9810\n",
      "       133     -779486.4054          +1.1561\n",
      "       134     -779485.0863          +1.3191\n",
      "       135     -779483.5167          +1.5695\n",
      "       136     -779482.1876          +1.3292\n",
      "       137     -779481.4701          +0.7175\n",
      "       138     -779480.7630          +0.7071\n",
      "       139     -779479.8791          +0.8839\n",
      "       140     -779478.6564          +1.2227\n",
      "       141     -779476.9913          +1.6651\n",
      "       142     -779474.9374          +2.0539\n",
      "       143     -779472.6581          +2.2792\n",
      "       144     -779470.5418          +2.1164\n",
      "       145     -779469.2578          +1.2839\n",
      "       146     -779468.7648          +0.4931\n",
      "       147     -779468.5647          +0.2000\n",
      "       148     -779468.4535          +0.1113\n",
      "       149     -779468.3765          +0.0769\n",
      "       150     -779468.3168          +0.0597\n",
      "       151     -779468.2675          +0.0493\n",
      "       152     -779468.2255          +0.0420\n",
      "       153     -779468.1890          +0.0365\n",
      "       154     -779468.1571          +0.0320\n",
      "       155     -779468.1289          +0.0282\n",
      "       156     -779468.1041          +0.0248\n",
      "       157     -779468.0821          +0.0219\n",
      "       158     -779468.0628          +0.0194\n",
      "       159     -779468.0457          +0.0171\n",
      "       160     -779468.0306          +0.0151\n",
      "       161     -779468.0172          +0.0134\n",
      "       162     -779468.0053          +0.0119\n",
      "       163     -779467.9947          +0.0106\n",
      "       164     -779467.9851          +0.0095\n",
      "         1     -936237.8662             +nan\n",
      "         2     -809098.6153     +127139.2509\n",
      "         3     -786053.6111      +23045.0042\n",
      "         4     -738262.8321      +47790.7790\n",
      "         5     -736736.1727       +1526.6594\n",
      "         6     -735887.0080        +849.1647\n",
      "         7     -735283.7890        +603.2191\n",
      "         8     -734904.7027        +379.0862\n",
      "         9     -734722.0479        +182.6549\n",
      "        10     -734567.1723        +154.8755\n",
      "        11     -734413.1174        +154.0549\n",
      "        12     -734308.3864        +104.7310\n",
      "        13     -734201.9649        +106.4215\n",
      "        14     -734108.0430         +93.9219\n",
      "        15     -734044.7895         +63.2535\n",
      "        16     -733993.2620         +51.5275\n",
      "        17     -733933.2783         +59.9837\n",
      "        18     -733868.7450         +64.5333\n",
      "        19     -733816.4207         +52.3243\n",
      "        20     -733774.6826         +41.7381\n",
      "        21     -733735.5910         +39.0916\n",
      "        22     -733681.3667         +54.2243\n",
      "        23     -733588.0456         +93.3211\n",
      "        24     -733505.1763         +82.8693\n",
      "        25     -733425.6175         +79.5588\n",
      "        26     -733352.4270         +73.1906\n",
      "        27     -733294.3134         +58.1136\n",
      "        28     -733250.9127         +43.4007\n",
      "        29     -733203.9206         +46.9921\n",
      "        30     -733149.2421         +54.6785\n",
      "        31     -733093.4687         +55.7734\n",
      "        32     -733041.9531         +51.5156\n",
      "        33     -732992.3676         +49.5855\n",
      "        34     -732943.9112         +48.4564\n",
      "        35     -732883.4090         +60.5022\n",
      "        36     -732819.7792         +63.6298\n",
      "        37     -732770.0251         +49.7541\n",
      "        38     -732730.4655         +39.5595\n",
      "        39     -732696.8839         +33.5816\n",
      "        40     -732680.6069         +16.2770\n",
      "        41     -732666.8485         +13.7584\n",
      "        42     -732654.7554         +12.0932\n",
      "        43     -732637.5690         +17.1864\n",
      "        44     -732625.3265         +12.2425\n",
      "        45     -732612.9135         +12.4131\n",
      "        46     -732602.0974         +10.8160\n",
      "        47     -732591.5262         +10.5712\n",
      "        48     -732574.2353         +17.2909\n",
      "        49     -732559.7403         +14.4950\n",
      "        50     -732546.3740         +13.3663\n",
      "        51     -732535.5913         +10.7827\n",
      "        52     -732529.0974          +6.4939\n",
      "        53     -732523.8706          +5.2268\n",
      "        54     -732518.8113          +5.0593\n",
      "        55     -732513.5783          +5.2330\n",
      "        56     -732508.6144          +4.9639\n",
      "        57     -732504.3897          +4.2247\n",
      "        58     -732501.1669          +3.2228\n",
      "        59     -732498.7800          +2.3869\n",
      "        60     -732496.9463          +1.8337\n",
      "        61     -732495.5123          +1.4340\n",
      "        62     -732494.3000          +1.2123\n",
      "        63     -732493.1513          +1.1487\n",
      "        64     -732491.9580          +1.1933\n",
      "        65     -732490.6558          +1.3023\n",
      "        66     -732489.1898          +1.4660\n",
      "        67     -732487.4125          +1.7773\n",
      "        68     -732485.8228          +1.5896\n",
      "        69     -732484.6524          +1.1705\n",
      "        70     -732482.6191          +2.0332\n",
      "        71     -732479.4729          +3.1462\n",
      "        72     -732477.3231          +2.1498\n",
      "        73     -732476.5348          +0.7883\n",
      "        74     -732476.0017          +0.5331\n",
      "        75     -732475.5201          +0.4817\n",
      "        76     -732475.0708          +0.4493\n",
      "        77     -732474.6484          +0.4224\n",
      "        78     -732474.2398          +0.4086\n",
      "        79     -732473.8132          +0.4266\n",
      "        80     -732473.2928          +0.5204\n",
      "        81     -732472.5040          +0.7888\n",
      "        82     -732471.4447          +1.0592\n",
      "        83     -732470.6368          +0.8079\n",
      "        84     -732470.0209          +0.6159\n",
      "        85     -732469.3893          +0.6316\n",
      "        86     -732468.5640          +0.8253\n",
      "        87     -732467.2045          +1.3595\n",
      "        88     -732465.6019          +1.6026\n",
      "        89     -732459.8544          +5.7475\n",
      "        90     -732442.7001         +17.1542\n",
      "        91     -732441.5917          +1.1084\n",
      "        92     -732441.1248          +0.4669\n",
      "        93     -732440.5291          +0.5957\n",
      "        94     -732439.6260          +0.9030\n",
      "        95     -732438.1150          +1.5111\n",
      "        96     -732435.5666          +2.5484\n",
      "        97     -732431.2029          +4.3637\n",
      "        98     -732424.6034          +6.5995\n",
      "        99     -732413.0071         +11.5963\n",
      "       100     -732391.0633         +21.9438\n",
      "       101     -732347.3180         +43.7453\n",
      "       102     -732307.3066         +40.0114\n",
      "       103     -732284.6517         +22.6548\n",
      "       104     -732271.9710         +12.6807\n",
      "       105     -732264.7688          +7.2022\n",
      "       106     -732257.0291          +7.7397\n",
      "       107     -732249.4987          +7.5304\n",
      "       108     -732247.6767          +1.8220\n",
      "       109     -732246.9181          +0.7586\n",
      "       110     -732246.4685          +0.4496\n",
      "       111     -732246.1053          +0.3632\n",
      "       112     -732245.7840          +0.3213\n",
      "       113     -732245.4853          +0.2987\n",
      "       114     -732245.1726          +0.3127\n",
      "       115     -732244.7908          +0.3818\n",
      "       116     -732244.2542          +0.5365\n",
      "       117     -732243.5104          +0.7438\n",
      "       118     -732242.5752          +0.9353\n",
      "       119     -732241.2008          +1.3744\n",
      "       120     -732239.0964          +2.1044\n",
      "       121     -732235.6928          +3.4036\n",
      "       122     -732230.0830          +5.6098\n",
      "       123     -732224.7913          +5.2917\n",
      "       124     -732220.9913          +3.8000\n",
      "       125     -732218.4376          +2.5537\n",
      "       126     -732217.5832          +0.8544\n",
      "       127     -732217.2516          +0.3316\n",
      "       128     -732217.0662          +0.1854\n",
      "       129     -732216.8507          +0.2155\n",
      "       130     -732216.5474          +0.3033\n",
      "       131     -732216.1201          +0.4273\n",
      "       132     -732215.5837          +0.5364\n",
      "       133     -732215.0873          +0.4964\n",
      "       134     -732214.7243          +0.3630\n",
      "       135     -732214.4438          +0.2805\n",
      "       136     -732214.2050          +0.2388\n",
      "       137     -732214.0027          +0.2023\n",
      "       138     -732213.8491          +0.1536\n",
      "       139     -732213.7448          +0.1043\n",
      "       140     -732213.6765          +0.0683\n",
      "       141     -732213.6304          +0.0460\n",
      "       142     -732213.5977          +0.0327\n",
      "       143     -732213.5728          +0.0249\n",
      "       144     -732213.5524          +0.0204\n",
      "       145     -732213.5340          +0.0184\n",
      "       146     -732213.5149          +0.0190\n",
      "       147     -732213.4908          +0.0241\n",
      "       148     -732213.4510          +0.0398\n",
      "       149     -732213.3660          +0.0850\n",
      "       150     -732213.1597          +0.2064\n",
      "       151     -732212.7465          +0.4132\n",
      "       152     -732212.3614          +0.3850\n",
      "       153     -732212.2468          +0.1147\n",
      "       154     -732212.2195          +0.0272\n",
      "       155     -732212.2076          +0.0119\n",
      "       156     -732212.2005          +0.0071\n",
      "         1     -991733.9570             +nan\n",
      "         2     -872027.3769     +119706.5801\n",
      "         3     -855370.8269      +16656.5500\n",
      "         4     -850613.6530       +4757.1739\n",
      "         5     -848618.5814       +1995.0716\n",
      "         6     -847712.1248        +906.4566\n",
      "         7     -847163.5377        +548.5872\n",
      "         8     -846648.8001        +514.7376\n",
      "         9     -846300.6948        +348.1053\n",
      "        10     -846104.2579        +196.4368\n",
      "        11     -845904.8732        +199.3847\n",
      "        12     -845727.2743        +177.5989\n",
      "        13     -845535.3600        +191.9143\n",
      "        14     -845327.2346        +208.1254\n",
      "        15     -845179.0548        +148.1798\n",
      "        16     -845040.3999        +138.6549\n",
      "        17     -844872.9548        +167.4451\n",
      "        18     -844715.5198        +157.4350\n",
      "        19     -844636.3390         +79.1808\n",
      "        20     -844570.1743         +66.1648\n",
      "        21     -844495.6662         +74.5080\n",
      "        22     -844417.9388         +77.7274\n",
      "        23     -844360.1726         +57.7662\n",
      "        24     -844314.8049         +45.3678\n",
      "        25     -844266.4368         +48.3681\n",
      "        26     -844197.7492         +68.6876\n",
      "        27     -844135.4564         +62.2928\n",
      "        28     -844053.7860         +81.6704\n",
      "        29     -843996.8227         +56.9633\n",
      "        30     -843957.5687         +39.2540\n",
      "        31     -843927.7024         +29.8664\n",
      "        32     -843899.1799         +28.5225\n",
      "        33     -843857.2675         +41.9124\n",
      "        34     -843829.5499         +27.7176\n",
      "        35     -843809.1148         +20.4351\n",
      "        36     -843788.7166         +20.3982\n",
      "        37     -843766.7911         +21.9256\n",
      "        38     -843740.4500         +26.3411\n",
      "        39     -843711.8696         +28.5804\n",
      "        40     -843682.7867         +29.0829\n",
      "        41     -843653.6605         +29.1262\n",
      "        42     -843626.8403         +26.8202\n",
      "        43     -843608.1630         +18.6773\n",
      "        44     -843595.4730         +12.6900\n",
      "        45     -843583.6282         +11.8448\n",
      "        46     -843570.0902         +13.5380\n",
      "        47     -843555.3094         +14.7808\n",
      "        48     -843536.2002         +19.1091\n",
      "        49     -843509.2007         +26.9996\n",
      "        50     -843493.8591         +15.3416\n",
      "        51     -843482.4986         +11.3605\n",
      "        52     -843463.2146         +19.2840\n",
      "        53     -843440.1964         +23.0182\n",
      "        54     -843426.7484         +13.4480\n",
      "        55     -843418.8242          +7.9243\n",
      "        56     -843411.2628          +7.5614\n",
      "        57     -843398.4662         +12.7966\n",
      "        58     -843397.3298          +1.1363\n",
      "        59     -843396.5899          +0.7399\n",
      "        60     -843395.9427          +0.6472\n",
      "        61     -843394.5769          +1.3658\n",
      "        62     -843384.9634          +9.6135\n",
      "        63     -843367.6153         +17.3481\n",
      "        64     -843357.8758          +9.7395\n",
      "        65     -843357.4961          +0.3797\n",
      "        66     -843357.0406          +0.4555\n",
      "        67     -843356.4164          +0.6241\n",
      "        68     -843355.5230          +0.8935\n",
      "        69     -843354.4114          +1.1116\n",
      "        70     -843353.2575          +1.1540\n",
      "        71     -843352.4460          +0.8115\n",
      "        72     -843351.5833          +0.8627\n",
      "        73     -843350.0192          +1.5640\n",
      "        74     -843346.5431          +3.4762\n",
      "        75     -843341.5053          +5.0378\n",
      "        76     -843334.5184          +6.9868\n",
      "        77     -843320.8896         +13.6288\n",
      "        78     -843311.6697          +9.2199\n",
      "        79     -843306.2708          +5.3989\n",
      "        80     -843303.0382          +3.2326\n",
      "        81     -843300.9931          +2.0451\n",
      "        82     -843299.9987          +0.9944\n",
      "        83     -843298.9061          +1.0926\n",
      "        84     -843298.6353          +0.2708\n",
      "        85     -843298.5844          +0.0509\n",
      "        86     -843298.5537          +0.0307\n",
      "        87     -843298.5276          +0.0261\n",
      "        88     -843298.4999          +0.0278\n",
      "        89     -843298.4644          +0.0354\n",
      "        90     -843298.4113          +0.0531\n",
      "        91     -843298.3218          +0.0895\n",
      "        92     -843298.1621          +0.1597\n",
      "        93     -843297.8375          +0.3245\n",
      "        94     -843296.9941          +0.8434\n",
      "        95     -843296.0251          +0.9690\n",
      "        96     -843295.7776          +0.2475\n",
      "        97     -843295.6116          +0.1660\n",
      "        98     -843295.4385          +0.1731\n",
      "        99     -843295.2229          +0.2156\n",
      "       100     -843294.9365          +0.2865\n",
      "       101     -843294.5654          +0.3711\n",
      "       102     -843294.0722          +0.4932\n",
      "       103     -843293.3479          +0.7243\n",
      "       104     -843291.7050          +1.6429\n",
      "       105     -843287.2247          +4.4803\n",
      "       106     -843280.8409          +6.3838\n",
      "       107     -843272.7301          +8.1108\n",
      "       108     -843265.0043          +7.7258\n",
      "       109     -843261.3208          +3.6834\n",
      "       110     -843260.1440          +1.1769\n",
      "       111     -843259.3539          +0.7900\n",
      "       112     -843258.5149          +0.8390\n",
      "       113     -843256.9210          +1.5940\n",
      "       114     -843250.0048          +6.9162\n",
      "       115     -843245.0617          +4.9432\n",
      "       116     -843241.8773          +3.1844\n",
      "       117     -843237.3971          +4.4801\n",
      "       118     -843232.6068          +4.7903\n",
      "       119     -843229.0181          +3.5887\n",
      "       120     -843226.1940          +2.8242\n",
      "       121     -843224.8445          +1.3495\n",
      "       122     -843223.8699          +0.9746\n",
      "       123     -843222.6694          +1.2005\n",
      "       124     -843220.8864          +1.7830\n",
      "       125     -843219.8929          +0.9935\n",
      "       126     -843218.9330          +0.9599\n",
      "       127     -843217.1316          +1.8014\n",
      "       128     -843215.4813          +1.6503\n",
      "       129     -843215.0899          +0.3914\n",
      "       130     -843214.8368          +0.2531\n",
      "       131     -843214.6517          +0.1851\n",
      "       132     -843214.5196          +0.1322\n",
      "       133     -843214.3482          +0.1714\n",
      "       134     -843214.0445          +0.3037\n",
      "       135     -843213.5841          +0.4604\n",
      "       136     -843213.0204          +0.5636\n",
      "       137     -843212.3317          +0.6887\n",
      "       138     -843211.5927          +0.7391\n",
      "       139     -843210.8563          +0.7364\n",
      "       140     -843209.9111          +0.9452\n",
      "       141     -843208.5685          +1.3426\n",
      "       142     -843207.2112          +1.3573\n",
      "       143     -843205.8371          +1.3741\n",
      "       144     -843203.4589          +2.3781\n",
      "       145     -843199.2670          +4.1919\n",
      "       146     -843188.9784         +10.2886\n",
      "       147     -843181.0109          +7.9675\n",
      "       148     -843178.4062          +2.6047\n",
      "       149     -843176.4989          +1.9073\n",
      "       150     -843172.9013          +3.5976\n",
      "       151     -843168.5183          +4.3829\n",
      "       152     -843164.0396          +4.4788\n",
      "       153     -843156.5821          +7.4575\n",
      "       154     -843146.0045         +10.5776\n",
      "       155     -843142.3254          +3.6791\n",
      "       156     -843140.9755          +1.3500\n",
      "       157     -843140.0359          +0.9395\n",
      "       158     -843139.3923          +0.6436\n",
      "       159     -843138.8428          +0.5495\n",
      "       160     -843138.2614          +0.5814\n",
      "       161     -843137.5498          +0.7116\n",
      "       162     -843136.7671          +0.7827\n",
      "       163     -843136.1394          +0.6277\n",
      "       164     -843135.4542          +0.6852\n",
      "       165     -843134.1227          +1.3315\n",
      "       166     -843131.7117          +2.4110\n",
      "       167     -843129.8422          +1.8695\n",
      "       168     -843128.3068          +1.5354\n",
      "       169     -843126.1181          +2.1886\n",
      "       170     -843124.8072          +1.3110\n",
      "       171     -843124.1145          +0.6927\n",
      "       172     -843123.5477          +0.5668\n",
      "       173     -843123.0643          +0.4834\n",
      "       174     -843122.7833          +0.2811\n",
      "       175     -843122.6833          +0.1000\n",
      "       176     -843122.6491          +0.0341\n",
      "       177     -843122.6362          +0.0130\n",
      "       178     -843122.6309          +0.0053\n",
      "         1    -1042892.4254             +nan\n",
      "         2     -907886.4996     +135005.9258\n",
      "         3     -885605.6232      +22280.8763\n",
      "         4     -880096.5135       +5509.1097\n",
      "         5     -878282.8825       +1813.6310\n",
      "         6     -877238.1271       +1044.7554\n",
      "         7     -876580.0589        +658.0683\n",
      "         8     -876158.9569        +421.1020\n",
      "         9     -875815.8215        +343.1353\n",
      "        10     -875541.7531        +274.0684\n",
      "        11     -875320.0071        +221.7460\n",
      "        12     -875158.5103        +161.4968\n",
      "        13     -875070.7680         +87.7423\n",
      "        14     -874996.3288         +74.4393\n",
      "        15     -874880.3744        +115.9544\n",
      "        16     -874732.5936        +147.7808\n",
      "        17     -874617.2162        +115.3773\n",
      "        18     -874535.7745         +81.4417\n",
      "        19     -874491.0515         +44.7230\n",
      "        20     -874450.2435         +40.8080\n",
      "        21     -874418.6991         +31.5444\n",
      "        22     -874394.9680         +23.7312\n",
      "        23     -874369.6454         +25.3226\n",
      "        24     -874343.5061         +26.1393\n",
      "        25     -874321.6520         +21.8541\n",
      "        26     -874306.3002         +15.3518\n",
      "        27     -874291.4374         +14.8628\n",
      "        28     -874272.3643         +19.0731\n",
      "        29     -874220.6352         +51.7291\n",
      "        30     -874162.8726         +57.7627\n",
      "        31     -874138.6761         +24.1964\n",
      "        32     -874125.9955         +12.6806\n",
      "        33     -874114.5645         +11.4309\n",
      "        34     -874105.2088          +9.3557\n",
      "        35     -874095.2950          +9.9138\n",
      "        36     -874083.4528         +11.8422\n",
      "        37     -874069.1685         +14.2843\n",
      "        38     -874036.2369         +32.9317\n",
      "        39     -873973.4523         +62.7846\n",
      "        40     -873920.9334         +52.5188\n",
      "        41     -873890.1118         +30.8216\n",
      "        42     -873866.3729         +23.7389\n",
      "        43     -873838.8236         +27.5493\n",
      "        44     -873809.9417         +28.8819\n",
      "        45     -873751.7489         +58.1927\n",
      "        46     -873714.1169         +37.6320\n",
      "        47     -873644.0307         +70.0862\n",
      "        48     -873570.5061         +73.5246\n",
      "        49     -873515.8903         +54.6158\n",
      "        50     -873442.9910         +72.8992\n",
      "        51     -873423.4320         +19.5590\n",
      "        52     -873406.0767         +17.3553\n",
      "        53     -873396.2326          +9.8441\n",
      "        54     -873390.7793          +5.4533\n",
      "        55     -873386.3110          +4.4683\n",
      "        56     -873383.4655          +2.8455\n",
      "        57     -873381.1518          +2.3138\n",
      "        58     -873379.3650          +1.7868\n",
      "        59     -873377.9011          +1.4638\n",
      "        60     -873376.8248          +1.0763\n",
      "        61     -873375.8750          +0.9498\n",
      "        62     -873374.9441          +0.9309\n",
      "        63     -873374.0634          +0.8807\n",
      "        64     -873373.3513          +0.7121\n",
      "        65     -873372.7790          +0.5723\n",
      "        66     -873372.2506          +0.5284\n",
      "        67     -873371.6991          +0.5515\n",
      "        68     -873371.0492          +0.6499\n",
      "        69     -873370.1764          +0.8728\n",
      "        70     -873369.2563          +0.9201\n",
      "        71     -873368.6299          +0.6264\n",
      "        72     -873368.1572          +0.4727\n",
      "        73     -873367.7803          +0.3769\n",
      "        74     -873367.4693          +0.3110\n",
      "        75     -873367.2028          +0.2665\n",
      "        76     -873366.9711          +0.2317\n",
      "        77     -873366.7729          +0.1982\n",
      "        78     -873366.6092          +0.1637\n",
      "        79     -873366.4766          +0.1326\n",
      "        80     -873366.3679          +0.1087\n",
      "        81     -873366.2767          +0.0912\n",
      "        82     -873366.1986          +0.0781\n",
      "        83     -873366.1305          +0.0680\n",
      "        84     -873366.0703          +0.0602\n",
      "        85     -873366.0161          +0.0542\n",
      "        86     -873365.9664          +0.0497\n",
      "        87     -873365.9200          +0.0464\n",
      "        88     -873365.8759          +0.0441\n",
      "        89     -873365.8334          +0.0425\n",
      "        90     -873365.7919          +0.0415\n",
      "        91     -873365.7513          +0.0406\n",
      "        92     -873365.7119          +0.0394\n",
      "        93     -873365.6743          +0.0377\n",
      "        94     -873365.6391          +0.0351\n",
      "        95     -873365.6072          +0.0319\n",
      "        96     -873365.5790          +0.0282\n",
      "        97     -873365.5547          +0.0244\n",
      "        98     -873365.5337          +0.0209\n",
      "        99     -873365.5158          +0.0180\n",
      "       100     -873365.5001          +0.0157\n",
      "       101     -873365.4862          +0.0139\n",
      "       102     -873365.4734          +0.0127\n",
      "       103     -873365.4616          +0.0119\n",
      "       104     -873365.4503          +0.0113\n",
      "       105     -873365.4394          +0.0109\n",
      "       106     -873365.4288          +0.0106\n",
      "       107     -873365.4184          +0.0104\n",
      "       108     -873365.4081          +0.0103\n",
      "       109     -873365.3977          +0.0104\n",
      "       110     -873365.3873          +0.0105\n",
      "       111     -873365.3765          +0.0107\n",
      "       112     -873365.3653          +0.0112\n",
      "       113     -873365.3533          +0.0121\n",
      "       114     -873365.3397          +0.0136\n",
      "       115     -873365.3232          +0.0165\n",
      "       116     -873365.3009          +0.0223\n",
      "       117     -873365.2653          +0.0356\n",
      "       118     -873365.1941          +0.0712\n",
      "       119     -873365.0029          +0.1913\n",
      "       120     -873364.2932          +0.7097\n",
      "       121     -873361.4386          +2.8546\n",
      "       122     -873353.7467          +7.6920\n",
      "       123     -873340.4046         +13.3420\n",
      "       124     -873322.3048         +18.0998\n",
      "       125     -873307.7414         +14.5633\n",
      "       126     -873295.8452         +11.8963\n",
      "       127     -873288.0175          +7.8276\n",
      "       128     -873276.3917         +11.6258\n",
      "       129     -873270.3681          +6.0236\n",
      "       130     -873267.0288          +3.3394\n",
      "       131     -873263.3445          +3.6842\n",
      "       132     -873259.7334          +3.6111\n",
      "       133     -873256.5380          +3.1954\n",
      "       134     -873254.6169          +1.9211\n",
      "       135     -873254.0594          +0.5575\n",
      "       136     -873253.9550          +0.1044\n",
      "       137     -873253.9339          +0.0211\n",
      "       138     -873253.9254          +0.0085\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đăng nhập\n",
      "TRUE PREDICT: 16/16\n",
      "ACCURACY: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đăng xuất\n",
      "TRUE PREDICT: 17/17\n",
      "ACCURACY: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khóa máy\n",
      "TRUE PREDICT: 17/17\n",
      "ACCURACY: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm kiếm\n",
      "TRUE PREDICT: 16/16\n",
      "ACCURACY: 1.0\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for cname in class_names:\n",
    "    hmm = GMMHMM(\n",
    "    n_components=param_dict[cname][0], n_mix = 4, random_state=42, n_iter=1000, verbose=True,\n",
    "        params='mctw',\n",
    "        init_params='mct'\n",
    "    )\n",
    "    hmm.startprob_ = param_dict[cname][1]\n",
    "    hmm.transmat_ = param_dict[cname][2]\n",
    "\n",
    "#     uncomment below line to train with full dataset\n",
    "    X = np.concatenate(dataset[cname])\n",
    "\n",
    "#     X = np.concatenate(dataset_train[cname])\\\n",
    "#     FOR GMMHMM: NO NEED lengths parameter\n",
    "    hmm.fit(X)\n",
    "    models[cname] = hmm\n",
    "print(\"Training done\")\n",
    "\n",
    "print(\"Testing\")\n",
    "\n",
    "for true_cname in class_names:\n",
    "    true_predict = 0\n",
    "#     for O in dataset[true_cname]:\n",
    "    for O in dataset_test[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items()}\n",
    "        predict = max(score, key=score.get)\n",
    "        if predict == true_cname:\n",
    "            true_predict += 1\n",
    "#         print(true_cname, score, predict)\n",
    "    print(true_cname)\n",
    "#     change dataset_test to dataset to test in full dataset\n",
    "    print(f'TRUE PREDICT: {true_predict}/{len(dataset_test[true_cname])}')\n",
    "    print('ACCURACY:', true_predict/len(dataset_test[true_cname]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Đăng nhập': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5,...\n",
       "        random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])),\n",
       " 'Đăng xuất': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5,...\n",
       "        random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])),\n",
       " 'Khóa máy': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5,...\n",
       "        min_covar=0.001, n_components=15, n_iter=1000, n_mix=4, params='mctw',\n",
       "        random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])),\n",
       " 'Tìm kiếm': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5,...\n",
       "        random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]))}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"model_predict_function.pkl\", \"wb\") as file:\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_test = pickle.load(open(\"model_predict_function.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Đăng nhập': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5,...\n",
       "        random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])),\n",
       " 'Đăng xuất': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5,...\n",
       "        random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])),\n",
       " 'Khóa máy': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5,...\n",
       "        min_covar=0.001, n_components=15, n_iter=1000, n_mix=4, params='mctw',\n",
       "        random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])),\n",
       " 'Tìm kiếm': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5,...\n",
       "        random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]))}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for true_cname in class_names:\n",
    "    true_predict = 0\n",
    "#     for O in dataset[true_cname]:\n",
    "    for O in dataset_record[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items()}\n",
    "        predict = max(score, key=score.get)\n",
    "        if predict == true_cname:\n",
    "            true_predict += 1\n",
    "#         print(true_cname, score, predict)\n",
    "    print(true_cname)\n",
    "#     change dataset_test to dataset to test in full dataset\n",
    "    print(f'TRUE PREDICT: {true_predict}/{len(dataset_record[true_cname])}')\n",
    "    print('ACCURACY:', true_predict/len(dataset_record[true_cname]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def remove_noise(file_path):\n",
    "#     print(file_path)\n",
    "    y,sr = librosa.load(file_path, duration=10)\n",
    "    y_filted = sp.signal.medfilt(y,3)\n",
    "    y_filted, index = librosa.effects.trim(y_filted, top_db=25)\n",
    "    # y, index = librosa.effects.trim(y, top_db=10)\n",
    "\n",
    "    # plot waveform\n",
    "#     plt.figure()\n",
    "#     plt.subplot(3,1,1)\n",
    "    # librosa.display.waveplot(y_filted, sr = sr)\n",
    "    new_path = file_path.split('.')[0]\n",
    "\n",
    "    # write file\n",
    "#     sf.write(new_path + '_removed.wav', y_filted, sr, 'PCM_24')\n",
    "    sf.write(file_path, y_filted, sr, 'PCM_24')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
