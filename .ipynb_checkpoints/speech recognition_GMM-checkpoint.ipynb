{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load toi dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load song dataset\n",
      "Load truoc dataset\n",
      "Load nhan_vien dataset\n",
      "Load gia_dinh dataset\n",
      "Load test_toi dataset\n",
      "Load test_song dataset\n",
      "Load test_truoc dataset\n",
      "Load test_nhan_vien dataset\n",
      "Load test_gia_dinh dataset\n",
      "vectors (21611, 36)\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"toi\", \"song\", \"truoc\", \"nhan_vien\", \"gia_dinh\", \"test_toi\", \"test_song\", \"test_truoc\", \n",
    "               \"test_nhan_vien\", \"test_gia_dinh\"]\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class toi\n",
      "(3490, 36) [22, 389, 36, 126, 28, 39, 98, 33, 23, 27, 21, 20, 23, 40, 36, 18, 25, 12, 22, 19, 14, 34, 22, 30, 47, 22, 29, 21, 17, 19, 31, 105, 24, 27, 19, 38, 25, 21, 84, 24, 22, 17, 17, 16, 142, 21, 36, 17, 18, 20, 18, 18, 32, 33, 29, 18, 47, 17, 19, 20, 18, 17, 49, 14, 31, 25, 18, 30, 24, 82, 26, 17, 16, 15, 24, 31, 16, 169, 20, 20, 149, 13, 123, 22, 34, 23, 131, 22, 24] 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -340834.8327             +nan\n",
      "         2     -318767.2881      +22067.5446\n",
      "         3     -312092.3800       +6674.9081\n",
      "         4     -310707.7561       +1384.6239\n",
      "         5     -310304.7026        +403.0534\n",
      "         6     -310121.1784        +183.5242\n",
      "         7     -309988.7226        +132.4558\n",
      "         8     -309918.3428         +70.3798\n",
      "         9     -309874.5546         +43.7881\n",
      "        10     -309838.6723         +35.8824\n",
      "        11     -309784.7330         +53.9393\n",
      "        12     -309709.1466         +75.5863\n",
      "        13     -309619.3101         +89.8366\n",
      "        14     -309456.2406        +163.0695\n",
      "        15     -309325.9262        +130.3144\n",
      "        16     -309256.0845         +69.8416\n",
      "        17     -309215.9093         +40.1753\n",
      "        18     -309174.5024         +41.4069\n",
      "        19     -309157.2758         +17.2266\n",
      "        20     -309142.8918         +14.3840\n",
      "        21     -309126.9358         +15.9560\n",
      "        22     -309112.2342         +14.7015\n",
      "        23     -309095.1159         +17.1184\n",
      "        24     -309084.6907         +10.4252\n",
      "        25     -309074.4962         +10.1945\n",
      "        26     -309065.2202          +9.2760\n",
      "        27     -309059.1678          +6.0524\n",
      "        28     -309054.7683          +4.3994\n",
      "        29     -309051.0621          +3.7062\n",
      "        30     -309047.7072          +3.3549\n",
      "        31     -309044.4489          +3.2583\n",
      "        32     -309040.4772          +3.9717\n",
      "        33     -309034.6345          +5.8427\n",
      "        34     -309024.9758          +9.6587\n",
      "        35     -309003.5536         +21.4222\n",
      "        36     -308975.2961         +28.2575\n",
      "        37     -308961.2341         +14.0620\n",
      "        38     -308959.0174          +2.2167\n",
      "        39     -308958.6637          +0.3537\n",
      "        40     -308958.0155          +0.6482\n",
      "        41     -308954.9200          +3.0955\n",
      "        42     -308954.4135          +0.5065\n",
      "        43     -308954.3825          +0.0311\n",
      "        44     -308954.3661          +0.0163\n",
      "        45     -308954.3554          +0.0107\n",
      "        46     -308954.3475          +0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class song\n",
      "(4580, 36) [25, 32, 47, 31, 24, 35, 54, 27, 35, 51, 34, 24, 25, 93, 188, 158, 17, 187, 46, 26, 31, 35, 30, 32, 28, 25, 31, 45, 30, 26, 43, 45, 168, 206, 33, 31, 35, 41, 43, 33, 46, 32, 82, 30, 47, 32, 47, 47, 42, 47, 41, 42, 33, 47, 36, 31, 122, 24, 36, 162, 30, 33, 34, 32, 27, 76, 44, 45, 30, 35, 31, 152, 43, 31, 163, 54, 30, 45, 26, 25, 44, 24, 17, 42, 26, 33, 42, 32, 31, 33, 43, 51] 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -452980.9075             +nan\n",
      "         2     -414897.8669      +38083.0407\n",
      "         3     -407005.5797       +7892.2872\n",
      "         4     -405287.8519       +1717.7277\n",
      "         5     -404517.5334        +770.3186\n",
      "         6     -404148.5407        +368.9927\n",
      "         7     -403983.7523        +164.7884\n",
      "         8     -403808.2416        +175.5106\n",
      "         9     -403692.0035        +116.2382\n",
      "        10     -403633.2687         +58.7347\n",
      "        11     -403593.2964         +39.9724\n",
      "        12     -403553.9078         +39.3886\n",
      "        13     -403516.4992         +37.4086\n",
      "        14     -403487.3322         +29.1669\n",
      "        15     -403465.7157         +21.6165\n",
      "        16     -403448.8027         +16.9131\n",
      "        17     -403436.2811         +12.5215\n",
      "        18     -403412.9258         +23.3554\n",
      "        19     -403367.0454         +45.8804\n",
      "        20     -403320.8928         +46.1526\n",
      "        21     -403290.2918         +30.6010\n",
      "        22     -403271.2889         +19.0030\n",
      "        23     -403245.8578         +25.4311\n",
      "        24     -403204.0645         +41.7933\n",
      "        25     -403190.6125         +13.4520\n",
      "        26     -403176.7204         +13.8920\n",
      "        27     -403169.7182          +7.0022\n",
      "        28     -403160.5464          +9.1718\n",
      "        29     -403157.3424          +3.2039\n",
      "        30     -403155.7300          +1.6125\n",
      "        31     -403153.6333          +2.0967\n",
      "        32     -403150.3619          +3.2713\n",
      "        33     -403142.3015          +8.0604\n",
      "        34     -403133.8435          +8.4580\n",
      "        35     -403130.2262          +3.6173\n",
      "        36     -403127.3639          +2.8623\n",
      "        37     -403124.3612          +3.0027\n",
      "        38     -403121.7261          +2.6351\n",
      "        39     -403117.9752          +3.7510\n",
      "        40     -403110.6935          +7.2816\n",
      "        41     -403100.3908         +10.3027\n",
      "        42     -403099.0177          +1.3731\n",
      "        43     -403098.4830          +0.5348\n",
      "        44     -403098.0448          +0.4381\n",
      "        45     -403097.5791          +0.4658\n",
      "        46     -403096.5648          +1.0142\n",
      "        47     -403089.2362          +7.3286\n",
      "        48     -403077.4904         +11.7458\n",
      "        49     -403074.8945          +2.5958\n",
      "        50     -403069.6088          +5.2857\n",
      "        51     -403059.8589          +9.7499\n",
      "        52     -403056.1803          +3.6786\n",
      "        53     -403054.6395          +1.5408\n",
      "        54     -403053.8389          +0.8006\n",
      "        55     -403053.2484          +0.5905\n",
      "        56     -403052.6572          +0.5912\n",
      "        57     -403051.9381          +0.7191\n",
      "        58     -403051.1024          +0.8357\n",
      "        59     -403050.4118          +0.6906\n",
      "        60     -403049.9773          +0.4346\n",
      "        61     -403049.6450          +0.3322\n",
      "        62     -403049.2088          +0.4362\n",
      "        63     -403048.1639          +1.0449\n",
      "        64     -403041.3436          +6.8203\n",
      "        65     -403020.4829         +20.8607\n",
      "        66     -403012.4734          +8.0095\n",
      "        67     -402986.9220         +25.5515\n",
      "        68     -402975.5103         +11.4117\n",
      "        69     -402972.0566          +3.4537\n",
      "        70     -402969.1326          +2.9241\n",
      "        71     -402966.6844          +2.4481\n",
      "        72     -402965.2895          +1.3949\n",
      "        73     -402963.6196          +1.6700\n",
      "        74     -402923.6115         +40.0081\n",
      "        75     -402822.4871        +101.1244\n",
      "        76     -402818.5588          +3.9283\n",
      "        77     -402818.4642          +0.0946\n",
      "        78     -402818.4204          +0.0437\n",
      "        79     -402817.6249          +0.7955\n",
      "        80     -402813.9881          +3.6368\n",
      "        81     -402813.5022          +0.4859\n",
      "        82     -402813.4845          +0.0177\n",
      "        83     -402813.4792          +0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class truoc\n",
      "(2227, 36) [27, 20, 41, 31, 24, 26, 41, 21, 31, 26, 18, 23, 32, 23, 26, 21, 21, 37, 36, 26, 31, 15, 17, 19, 23, 41, 25, 31, 31, 26, 31, 26, 19, 35, 21, 22, 24, 20, 11, 31, 31, 22, 29, 33, 22, 29, 22, 23, 24, 31, 21, 31, 26, 25, 20, 27, 19, 28, 27, 36, 25, 35, 23, 31, 21, 41, 41, 36, 27, 61, 43, 43, 35, 36, 20, 19, 19, 46, 31, 18] 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -232554.4634             +nan\n",
      "         2     -218867.2962      +13687.1672\n",
      "         3     -216799.9090       +2067.3872\n",
      "         4     -216277.6967        +522.2122\n",
      "         5     -215951.9161        +325.7807\n",
      "         6     -215832.9915        +118.9246\n",
      "         7     -215775.2629         +57.7286\n",
      "         8     -215722.5153         +52.7476\n",
      "         9     -215685.7548         +36.7605\n",
      "        10     -215663.6519         +22.1029\n",
      "        11     -215647.2387         +16.4132\n",
      "        12     -215635.2951         +11.9435\n",
      "        13     -215626.5996          +8.6955\n",
      "        14     -215618.5580          +8.0416\n",
      "        15     -215603.3089         +15.2491\n",
      "        16     -215584.5649         +18.7440\n",
      "        17     -215575.9814          +8.5834\n",
      "        18     -215571.8096          +4.1718\n",
      "        19     -215567.9441          +3.8655\n",
      "        20     -215562.5760          +5.3681\n",
      "        21     -215556.7056          +5.8704\n",
      "        22     -215552.3035          +4.4021\n",
      "        23     -215544.9913          +7.3121\n",
      "        24     -215532.5339         +12.4575\n",
      "        25     -215519.7178         +12.8161\n",
      "        26     -215508.5985         +11.1193\n",
      "        27     -215495.1435         +13.4550\n",
      "        28     -215482.7423         +12.4012\n",
      "        29     -215472.5413         +10.2010\n",
      "        30     -215461.9987         +10.5426\n",
      "        31     -215450.6409         +11.3578\n",
      "        32     -215439.9416         +10.6993\n",
      "        33     -215428.2759         +11.6657\n",
      "        34     -215418.3046          +9.9713\n",
      "        35     -215411.0553          +7.2493\n",
      "        36     -215397.8589         +13.1964\n",
      "        37     -215389.7073          +8.1516\n",
      "        38     -215386.9237          +2.7836\n",
      "        39     -215384.8973          +2.0263\n",
      "        40     -215382.7094          +2.1879\n",
      "        41     -215379.4851          +3.2243\n",
      "        42     -215377.6318          +1.8533\n",
      "        43     -215376.4302          +1.2016\n",
      "        44     -215374.9252          +1.5050\n",
      "        45     -215373.3291          +1.5961\n",
      "        46     -215372.2410          +1.0881\n",
      "        47     -215371.6361          +0.6049\n",
      "        48     -215371.2520          +0.3841\n",
      "        49     -215370.9400          +0.3120\n",
      "        50     -215370.6274          +0.3126\n",
      "        51     -215370.2238          +0.4036\n",
      "        52     -215369.5085          +0.7152\n",
      "        53     -215367.8989          +1.6097\n",
      "        54     -215364.6310          +3.2678\n",
      "        55     -215360.6273          +4.0038\n",
      "        56     -215355.9232          +4.7040\n",
      "        57     -215351.3896          +4.5336\n",
      "        58     -215348.8469          +2.5428\n",
      "        59     -215347.1882          +1.6586\n",
      "        60     -215345.5374          +1.6508\n",
      "        61     -215344.2328          +1.3047\n",
      "        62     -215343.2967          +0.9361\n",
      "        63     -215342.4015          +0.8951\n",
      "        64     -215341.3799          +1.0217\n",
      "        65     -215340.2398          +1.1401\n",
      "        66     -215339.0779          +1.1619\n",
      "        67     -215337.8917          +1.1863\n",
      "        68     -215336.8520          +1.0397\n",
      "        69     -215336.2868          +0.5651\n",
      "        70     -215336.0136          +0.2733\n",
      "        71     -215335.8720          +0.1416\n",
      "        72     -215335.7984          +0.0736\n",
      "        73     -215335.7593          +0.0390\n",
      "        74     -215335.7379          +0.0214\n",
      "        75     -215335.7258          +0.0121\n",
      "        76     -215335.7187          +0.0071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class nhan_vien\n",
      "(3622, 36) [50, 53, 65, 29, 33, 53, 50, 55, 47, 31, 44, 42, 36, 42, 46, 32, 40, 37, 55, 42, 39, 36, 29, 55, 43, 68, 33, 55, 55, 43, 53, 48, 55, 48, 53, 44, 34, 62, 40, 49, 35, 50, 41, 38, 44, 42, 53, 55, 30, 50, 78, 35, 52, 56, 40, 44, 50, 36, 34, 47, 63, 35, 65, 29, 36, 37, 34, 35, 63, 44, 45, 38, 40, 43, 47, 38, 39, 44, 38, 43, 32] 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -357113.2845             +nan\n",
      "         2     -344355.7306      +12757.5539\n",
      "         3     -340497.7097       +3858.0209\n",
      "         4     -339283.8129       +1213.8968\n",
      "         5     -338770.2195        +513.5934\n",
      "         6     -338561.6499        +208.5697\n",
      "         7     -338403.2590        +158.3908\n",
      "         8     -338274.0271        +129.2319\n",
      "         9     -338186.9896         +87.0375\n",
      "        10     -338130.0938         +56.8958\n",
      "        11     -338080.8417         +49.2521\n",
      "        12     -338037.5301         +43.3116\n",
      "        13     -338007.1065         +30.4236\n",
      "        14     -337982.2634         +24.8431\n",
      "        15     -337954.4470         +27.8164\n",
      "        16     -337917.6689         +36.7782\n",
      "        17     -337862.8539         +54.8150\n",
      "        18     -337833.3520         +29.5019\n",
      "        19     -337814.8777         +18.4743\n",
      "        20     -337797.6512         +17.2265\n",
      "        21     -337784.2154         +13.4358\n",
      "        22     -337768.7645         +15.4508\n",
      "        23     -337750.4878         +18.2767\n",
      "        24     -337726.2737         +24.2141\n",
      "        25     -337700.2180         +26.0557\n",
      "        26     -337678.0000         +22.2180\n",
      "        27     -337667.6964         +10.3036\n",
      "        28     -337661.6408          +6.0556\n",
      "        29     -337656.6293          +5.0115\n",
      "        30     -337651.8109          +4.8184\n",
      "        31     -337648.5945          +3.2164\n",
      "        32     -337646.2590          +2.3355\n",
      "        33     -337642.5936          +3.6654\n",
      "        34     -337633.6936          +8.9001\n",
      "        35     -337622.6045         +11.0890\n",
      "        36     -337614.0636          +8.5410\n",
      "        37     -337609.5943          +4.4693\n",
      "        38     -337606.8171          +2.7772\n",
      "        39     -337606.4402          +0.3768\n",
      "        40     -337606.2668          +0.1734\n",
      "        41     -337606.0955          +0.1713\n",
      "        42     -337605.7524          +0.3430\n",
      "        43     -337603.8203          +1.9322\n",
      "        44     -337599.8674          +3.9529\n",
      "        45     -337598.2937          +1.5736\n",
      "        46     -337597.6674          +0.6263\n",
      "        47     -337597.4331          +0.2343\n",
      "        48     -337597.3309          +0.1022\n",
      "        49     -337597.2798          +0.0511\n",
      "        50     -337597.2496          +0.0303\n",
      "        51     -337597.2283          +0.0212\n",
      "        52     -337597.2112          +0.0172\n",
      "        53     -337597.1955          +0.0157\n",
      "        54     -337597.1795          +0.0160\n",
      "        55     -337597.1614          +0.0181\n",
      "        56     -337597.1388          +0.0226\n",
      "        57     -337597.1084          +0.0304\n",
      "        58     -337597.0652          +0.0432\n",
      "        59     -337597.0037          +0.0615\n",
      "        60     -337596.9237          +0.0801\n",
      "        61     -337596.8388          +0.0849\n",
      "        62     -337596.7718          +0.0670\n",
      "        63     -337596.7319          +0.0399\n",
      "        64     -337596.7117          +0.0203\n",
      "        65     -337596.7017          +0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class gia_dinh\n",
      "(3826, 36) [51, 46, 55, 43, 35, 66, 41, 76, 47, 40, 46, 71, 45, 51, 40, 51, 41, 41, 53, 47, 61, 37, 51, 51, 51, 47, 36, 44, 43, 46, 46, 43, 39, 49, 44, 46, 51, 53, 37, 49, 33, 51, 51, 37, 46, 41, 66, 39, 37, 49, 45, 47, 31, 41, 41, 46, 45, 71, 43, 66, 51, 56, 49, 51, 71, 33, 55, 35, 49, 41, 41, 51, 51, 61, 45, 43, 61, 41, 66, 39] 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -404592.9311             +nan\n",
      "         2     -382758.9895      +21833.9416\n",
      "         3     -378482.3495       +4276.6400\n",
      "         4     -377143.1165       +1339.2330\n",
      "         5     -376416.8424        +726.2741\n",
      "         6     -376066.7585        +350.0838\n",
      "         7     -375864.1540        +202.6045\n",
      "         8     -375765.6344         +98.5197\n",
      "         9     -375738.9436         +26.6907\n",
      "        10     -375730.3438          +8.5998\n",
      "        11     -375724.3679          +5.9759\n",
      "        12     -375721.9445          +2.4234\n",
      "        13     -375719.5501          +2.3944\n",
      "        14     -375716.4462          +3.1039\n",
      "        15     -375714.1454          +2.3008\n",
      "        16     -375711.3659          +2.7796\n",
      "        17     -375706.5048          +4.8611\n",
      "        18     -375700.6679          +5.8368\n",
      "        19     -375695.2040          +5.4640\n",
      "        20     -375688.1472          +7.0568\n",
      "        21     -375679.6629          +8.4843\n",
      "        22     -375677.7284          +1.9345\n",
      "        23     -375677.3937          +0.3347\n",
      "        24     -375677.3260          +0.0678\n",
      "        25     -375677.2948          +0.0312\n",
      "        26     -375677.2783          +0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        27     -375677.2691          +0.0092\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for cname in class_names:\n",
    "    hmm = hmmlearn.hmm.GMMHMM(\n",
    "        n_mix = 2, random_state=42, n_iter=1000, verbose=True,\n",
    "        params='mctw',\n",
    "        init_params='mst',\n",
    "    )\n",
    "    \n",
    "    if cname == 'truoc':\n",
    "        hmm.n_components = 6\n",
    "        hmm.startprob_ = np.array([0.8, 0.2, 0.0, 0.0, 0.0, 0.0])\n",
    "        hmm.transmat_ = np.array([\n",
    "                [0.7,0.3,0.0,0.0,0.0,0.0],\n",
    "                [0.0,0.7,0.3,0.0,0.0,0.0],\n",
    "                [0.0,0.0,0.7,0.3,0.0,0.0],\n",
    "                [0.0,0.0,0.0,1.0,0.0,0.0],\n",
    "                [0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "                [0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "            ])\n",
    "    else:\n",
    "        hmm.n_components = 7\n",
    "        hmm.startprob_ = np.array([1.0,0.0,0.0,0.0,0.0, 0.0,0.0])\n",
    "        hmm.transmat_ = np.array([\n",
    "                [0.7,0.3,0.0,0.0,0.0,0.0,0.0],\n",
    "                [0.0,0.7,0.3,0.0,0.0,0.0,0.0],\n",
    "                [0.0,0.0,0.7,0.3,0.0,0.0,0.0],\n",
    "                [0.0,0.0,0.0,0.7,0.3,0.0,0.0],\n",
    "                [0.0,0.0,0.0,0.0,0.7,0.3,0.0],\n",
    "                [0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "                [0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "            ])\n",
    "\n",
    "    if cname[:4] != 'test':\n",
    "        X = np.concatenate(dataset[cname])\n",
    "        lengths = list([len(x) for x in dataset[cname]])\n",
    "        print(\"training class\", cname)\n",
    "        print(X.shape, lengths, len(lengths))\n",
    "        hmm.fit(X)\n",
    "        models[cname] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "test_toi   20\n",
      "test_gia_dinh   20\n",
      "test_nhan_vien   21\n",
      "test_song   20\n",
      "test_truoc   20\n",
      "{'test_toi': 100.0, 'test_gia_dinh': 100.0, 'test_nhan_vien': 100.0, 'test_song': 100.0, 'test_truoc': 100.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "acc = {}\n",
    "test_name = { \"test_toi\", \"test_song\", \"test_truoc\", \"test_nhan_vien\", \"test_gia_dinh\"}\n",
    "for true_cname in test_name:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "#         print(true_cname, score, pre)\n",
    "        if pre == true_cname[5:]:\n",
    "            kt +=1\n",
    "    print(true_cname,\" \", kt)\n",
    "    acc[true_cname] = kt * 100 / len(dataset[true_cname])\n",
    "print(acc)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toi': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'song': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'truoc': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=6, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'nhan_vien': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'gia_dinh': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]]))}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "toi   89\n",
      "song   92\n",
      "truoc   80\n",
      "nhan_vien   81\n",
      "gia_dinh   79\n",
      "{'toi': 100.0, 'song': 100.0, 'truoc': 100.0, 'nhan_vien': 100.0, 'gia_dinh': 98.75}\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "miss = {}\n",
    "acc = {}\n",
    "class_names = [\"toi\", \"song\", \"truoc\", \"nhan_vien\", \"gia_dinh\"]\n",
    "for true_cname in class_names:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "#         print(true_cname, score, pre)\n",
    "        if pre == true_cname:\n",
    "            kt +=1\n",
    "    print(true_cname,\" \", kt)\n",
    "    acc[true_cname] = kt * 100 / len(dataset[true_cname])\n",
    "print(acc)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toi'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = get_mfcc('data.wav')\n",
    "score = {cname: model.score(O, [len(O)]) for cname, model in models.items()}\n",
    "inverse = [(value, key) for key, value in score.items()]\n",
    "predict = max(inverse)[1]\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test_toi dataset\n",
      "vectors (895, 36)\n",
      "Testing\n",
      "test_toi {'toi': -7620.212225111643, 'song': -8230.521415545485, 'truoc': -8180.114885381267, 'nhan_vien': -8055.198681860034, 'gia_dinh': -8394.809761647619} toi\n",
      "test_toi {'toi': -2149.219995999329, 'song': -2412.9368211004685, 'truoc': -2349.830841056273, 'nhan_vien': -2303.6970214219964, 'gia_dinh': -2363.120670330845} toi\n",
      "test_toi {'toi': -4754.502610596342, 'song': -5116.315693293601, 'truoc': -5270.077827972711, 'nhan_vien': -5237.692756976712, 'gia_dinh': -4976.711196599017} toi\n",
      "test_toi {'toi': -1351.7292054794661, 'song': -1544.0518867550961, 'truoc': -1363.8936940397136, 'nhan_vien': -1426.545629349316, 'gia_dinh': -1475.5824434061235} toi\n",
      "test_toi {'toi': -2143.280006319747, 'song': -2328.4712382758908, 'truoc': -2236.9943185034103, 'nhan_vien': -2233.811970473114, 'gia_dinh': -2324.3715712918483} toi\n",
      "test_toi {'toi': -8820.564295791386, 'song': -9605.533709422523, 'truoc': -9826.687406909248, 'nhan_vien': -9616.831028032006, 'gia_dinh': -9375.206622770245} toi\n",
      "test_toi {'toi': -2069.5594524985504, 'song': -2242.3621953738175, 'truoc': -2195.0098644027585, 'nhan_vien': -2168.5605912476267, 'gia_dinh': -2280.2997491272645} toi\n",
      "test_toi {'toi': -1648.5222531713205, 'song': -1848.7494146082252, 'truoc': -1793.424017458523, 'nhan_vien': -1775.2110488377677, 'gia_dinh': -1809.327739840239} toi\n",
      "test_toi {'toi': -11197.267099110528, 'song': -12506.81858905508, 'truoc': -12441.294980450311, 'nhan_vien': -12336.443860250385, 'gia_dinh': -12673.002387402235} toi\n",
      "test_toi {'toi': -3578.380490444765, 'song': -3687.392706508314, 'truoc': -3798.529146434737, 'nhan_vien': -3604.1534383127887, 'gia_dinh': -3687.1969087526713} toi\n",
      "test_toi {'toi': -1660.1329564515217, 'song': -1787.282081670068, 'truoc': -1785.418789344101, 'nhan_vien': -1725.2274217772508, 'gia_dinh': -1660.4557980246436} toi\n",
      "test_toi {'toi': -1965.4204392352544, 'song': -2192.2286103568154, 'truoc': -2180.2056227798066, 'nhan_vien': -2150.5131991189965, 'gia_dinh': -2194.751003454861} toi\n",
      "test_toi {'toi': -2872.6013775332067, 'song': -3101.5967029959556, 'truoc': -3136.9124373777804, 'nhan_vien': -3084.2568805620344, 'gia_dinh': -3131.8406339020194} toi\n",
      "test_toi {'toi': -3141.133185969157, 'song': -3485.322137102206, 'truoc': -3433.9490718729194, 'nhan_vien': -3264.497107634756, 'gia_dinh': -3417.420818533449} toi\n",
      "test_toi {'toi': -5987.35172020553, 'song': -6470.820229200312, 'truoc': -6597.931413060539, 'nhan_vien': -6553.3051766719445, 'gia_dinh': -6549.155790545381} toi\n",
      "test_toi {'toi': -2179.252504098013, 'song': -2409.034512792424, 'truoc': -2426.2983271879907, 'nhan_vien': -2407.8786648227974, 'gia_dinh': -2477.454439062274} toi\n",
      "test_toi {'toi': -5220.308773905552, 'song': -5610.727159225282, 'truoc': -5463.763858211838, 'nhan_vien': -5366.820821370678, 'gia_dinh': -5464.965975565016} toi\n",
      "test_toi {'toi': -2728.4369285261128, 'song': -2886.119989182102, 'truoc': -2869.6994251981346, 'nhan_vien': -2876.0034908249545, 'gia_dinh': -3000.794752973401} toi\n",
      "test_toi {'toi': -6652.918530670467, 'song': -7194.208580314377, 'truoc': -7349.481849273729, 'nhan_vien': -7307.294100885237, 'gia_dinh': -7554.829966276977} toi\n",
      "test_toi {'toi': -3471.632892733901, 'song': -3770.7778292189487, 'truoc': -3690.747682176042, 'nhan_vien': -3550.5078720265396, 'gia_dinh': -3517.094550167726} toi\n",
      "test_toi   20\n",
      "{'test_toi': 100.0}\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"test_toi\"]\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    \n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n",
    "\n",
    "print(\"Testing\")\n",
    "acc = {}\n",
    "test_name = { \"test_toi\"}\n",
    "for true_cname in test_name:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "        print(true_cname, score, pre)\n",
    "        if pre == true_cname[5:]:\n",
    "            kt +=1\n",
    "    print(true_cname,\" \", kt)\n",
    "    acc[true_cname] = kt * 100 / len(dataset[true_cname])\n",
    "print(acc)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('output1.txt', 'w') as f:\n",
    "#     print(models, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# with open(\"output2.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence\n",
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Iterable\n",
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, namedtuple, defaultdict, Sequence\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"output_final.pkl\", \"rb\") as file:\n",
    "    models = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toi': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'song': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'truoc': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=6, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'nhan_vien': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'gia_dinh': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]]))}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
